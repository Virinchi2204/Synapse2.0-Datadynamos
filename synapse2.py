from flask import Flask, render_template, request
from transformers import MarianMTModel, MarianTokenizer
from transformers import pipeline
from translate import Translator
from torch import cuda
import transformers
import pandas as pd
import matplotlib as plt
import seaborn as sb
import matplotlib.pyplot as ppl
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import CategoricalNB
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfTransformer
import re
app = Flask(__name__)
tfidf_vectorizer = TfidfVectorizer()


def clean_text(text):
    cleaned_text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    return cleaned_text

json_file = 'SubtaskB\subtaskB_train.jsonl'
tdf = pd.read_json(json_file, lines=True)

json_file2 = 'SubtaskB\subtaskB_dev.jsonl'
ddf = pd.read_json(json_file, lines=True)

X_train = tdf['text'].values
y_train = tdf['label'].values

X_train_tfidf=tfidf_vectorizer.fit_transform(X_train)

classifier = MultinomialNB()
classifier.fit(X_train_tfidf, y_train)

label_mapping = {
    1:"chatGPT",
    0:"human",
    2:"cohere",
    3:"davinci",
    4:"bloomz",
    5:"dolly",
    # Add more labels as needed
}


@app.route("/")
def home():
    return render_template("index.html")


@app.route("/chat", methods=["POST"])
def chat():
    user_input = request.form.get("user_input")
    user_input_vectorized = tfidf_vectorizer.transform([user_input])
    prediction = classifier.predict(user_input_vectorized)
    response = f"text is generated by {label_mapping[prediction[0]]}"
    return render_template("index.html", user_input=user_input, response=response)


if __name__ == "__main__":
    app.run(debug=True)
